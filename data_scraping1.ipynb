{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind and Temperature testing data scraping using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read position files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # regular expression\n",
    "\n",
    "def split(text):\n",
    "    list_text = re.split(r\"\\n|\\s\", text)\n",
    "    return list_text[2], list_text[5]\n",
    "    \n",
    "position_bkk = {'lat': None, 'long': None}\n",
    "position_cm = {'lat': None, 'long': None}\n",
    "position_kk = {'lat': None, 'long': None}\n",
    "position_ry = {'lat': None, 'long': None}\n",
    "position_sb = {'lat': None, 'long': None}\n",
    "position_sr = {'lat': None, 'long': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_bkk = open('./datasci_dataset_2022/BKK/position.txt', 'r')\n",
    "f_cm = open('./datasci_dataset_2022/Chiangmai/position.txt', 'r')\n",
    "f_kk = open('./datasci_dataset_2022/Khonkaen/position.txt', 'r')\n",
    "f_ry = open('./datasci_dataset_2022/Rayong/position.txt', 'r')\n",
    "f_sb = open('./datasci_dataset_2022/Saraburi/position.txt', 'r')\n",
    "f_sr = open('./datasci_dataset_2022/Surat/position.txt', 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_bkk['lat'], position_bkk['long'] = split(f_bkk.read())\n",
    "position_cm['lat'], position_cm['long'] = split(f_cm.read())\n",
    "position_kk['lat'], position_kk['long'] = split(f_kk.read())\n",
    "position_ry['lat'], position_ry['long'] = split(f_ry.read())\n",
    "position_sb['lat'], position_sb['long'] = split(f_sb.read())\n",
    "position_sr['lat'], position_sr['long'] = split(f_sr.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BKK: {'lat': '13.729984', 'long': '100.536443'}\n",
      "Chiangmai: {'lat': '18.840633', 'long': '98.969661'}\n",
      "Khonkaen: {'lat': '16.445329', 'long': '102.835251'}\n",
      "Rayong: {'lat': '12.671521', 'long': '101.275875'}\n",
      "Saraburi: {'lat': '14.685833', 'long': '100.871996'}\n",
      "Surat: {'lat': '9.126057', 'long': '99.325355'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"BKK: {position_bkk}\\nChiangmai: {position_cm}\\nKhonkaen: {position_kk}\\nRayong: {position_ry}\\nSaraburi: {position_sb}\\nSurat: {position_sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_bkk.close()\n",
    "f_cm.close()\n",
    "f_kk.close()\n",
    "f_ry.close()\n",
    "f_sb.close()\n",
    "f_sr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current edge version is 99.0.1150\n",
      "[WDM] - Get LATEST edgedriver version for 99.0.1150 Edge\n",
      "[WDM] - Trying to download new driver from https://msedgedriver.azureedge.net/99.0.1150.39/edgedriver_win64.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\FACT-PC\\.wdm\\drivers\\edgedriver\\win64\\99.0.1150.39]\n"
     ]
    }
   ],
   "source": [
    "service = Service(executable_path=EdgeChromiumDriverManager().install())\n",
    "driver = webdriver.Edge(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30 18:00:00+00:00 2021-07-01 15:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "start_date, end_date = pd.to_datetime(['2020-07-01 01:00 +0700', '2021-07-01 22:00 +0700'], utc=True)  # Convert the data to datetime in UTC  \n",
    "print(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scrape_wind(date, lat, long):\n",
    "    url =  f'https://classic.nullschool.net/{date}/wind/isobaric/850hPa/orthographic/loc={long},{lat}'\n",
    "    driver.get(url)\n",
    "    driver.refresh()\n",
    "    wind_el = driver.find_element(by=By.CSS_SELECTOR, value='#location-wind')\n",
    "    wind_info = wind_el.get_attribute('innerText').split('Â° @ ')\n",
    "    return wind_info\n",
    "\n",
    "def scrape_wind_data(start_date, end_date, position, f_dir):\n",
    "    path = f'./datasci_dataset_2022/{f_dir.capitalize()}/test/{f_dir}_wind_test.csv'\n",
    "    \n",
    "    if (not os.path.exists(path) or os.stat(path).st_size==0):\n",
    "        f_w = open(path, 'a')\n",
    "        f_w.write('date_time,wind speed,wind dir\\n')\n",
    "        f_w.close()\n",
    "    else:\n",
    "        f_r = open(path, 'r')\n",
    "        last_line = f_r.readlines()[-1][:-1]\n",
    "        print(f\"lastline: {last_line}\")\n",
    "        if (last_line == 'date_time,wind speed,wind dir'):\n",
    "            pass\n",
    "        else:\n",
    "            last_date = pd.to_datetime([last_line[:16] + \" +0700\"], utc=True)\n",
    "            start_date = last_date[0] + pd.Timedelta(hours=3)\n",
    "\n",
    "    counter = 0\n",
    "    f_w = open(path, 'a')\n",
    "    while start_date <= end_date :\n",
    "        scrape_date = start_date.strftime('#%Y/%m/%d/%H%MZ')\n",
    "        save_date = start_date.tz_convert('Asia/Bangkok').strftime('%Y-%m-%d %H:%M:%S')\n",
    "        while True:\n",
    "            wind_info = scrape_wind(scrape_date, position['lat'], position['long'])\n",
    "            if len(wind_info) == 2: # if we have got the data, break the loop\n",
    "                break\n",
    "        start_date += pd.Timedelta(hours=3)\n",
    "        f_w.write(f\"{save_date},{wind_info[1]},{wind_info[0]}\\n\")\n",
    "        if counter == 7:   # Save the data once a day\n",
    "            counter = 0\n",
    "            f_w.close()\n",
    "            f_w = open(path, 'a')\n",
    "        else:\n",
    "            counter += 1\n",
    "        print(f\"{save_date},{wind_info[1]},{wind_info[0]}\")\n",
    "    f_w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape wind data for BKK\n",
    "scrape_wind_data(start_date, end_date, position_bkk, 'bkk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape wind data for Chiangmai\n",
    "scrape_wind_data(start_date, end_date, position_cm, 'chiangmai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape wind data for Khonkaen\n",
    "scrape_wind_data(start_date, end_date, position_kk, 'khonkaen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape wind data for Rayong\n",
    "scrape_wind_data(start_date, end_date, position_ry, 'rayong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape wind data for Saraburi\n",
    "scrape_wind_data(start_date, end_date, position_sb, 'saraburi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape wind data for Surat\n",
    "scrape_wind_data(start_date, end_date, position_sr, 'surat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()  # Close the selenium"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2594fca41359fbaf0c8b5f809cf3edce024c2b7d49fe63f1f071c1881f7b3daa"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
