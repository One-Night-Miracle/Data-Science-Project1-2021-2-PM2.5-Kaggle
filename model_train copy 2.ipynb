{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xXgecYKfoECO"
   },
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('clean_dataset_2022/train_set.bin', 'rb'))\n",
    "\n",
    "test_data = pickle.load(open('clean_dataset_2022/test_set.bin', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVf1rACoZREf"
   },
   "source": [
    "## SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5YThJtVMZlap"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "province = ['BKK','CNX','KKC','RAY','SARA','SURAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in province:\n",
    "    train_data[p] = train_data[p].resample('6H').mean()\n",
    "\n",
    "    tmp_df = test_data[p].copy()\n",
    "    tmp_df['PM25'] = test_data[p]['PM25'].asfreq(freq='6H')\n",
    "    test_data[p] = test_data[p].resample('6H').mean()\n",
    "    test_data[p]['PM25'] = tmp_df['PM25']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = {} ; valid_set = {}\n",
    "\n",
    "ratio = 0.7\n",
    "\n",
    "for p in province:\n",
    "    train_size, valid_size = int(ratio*train_data[p].shape[0]), int((1-ratio)*train_data[p].shape[0])\n",
    "    train_set[p], valid_set[p] = train_data[p].iloc[:train_size], train_data[p].iloc[train_size: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 6 provinces with *minimal_SARIMAX*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_function import minimalSARIMAX\n",
    "\n",
    "reload(minimalSARIMAX)\n",
    "\n",
    "from custom_function.minimalSARIMAX import MinimalSARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [(2, 0, 0), (2, 1, 0), (2, 1, 0), (2, 1, 0), (1, 0, 1), (2, 0, 0)]\n",
    "seasonal_order = [(1, 0, 0, 1461), (0, 1, 1, 1461), (0, 1, 1, 1461), (0, 0, 0, 1461), (0, 0, 0, 1461), (0, 1, 0, 1461)]\n",
    "\n",
    "exog_order = {}\n",
    "exog_order['Temp'] = [(1, 1, 0), (1, 1, 0), (1, 1, 0), (1, 0, 0), (1, 1, 0), (1, 1, 0)]\n",
    "exog_order['WindSpeed'] = [(1, 1, 0), (1, 1, 0), (1, 1, 0), (1, 1, 0), (1, 0, 0), (1, 1, 0)]\n",
    "exog_order['WindDir'] = [(1, 1, 0), (1, 0, 0), (2, 0, 0), (1, 1, 0), (1, 0, 0), (1, 0, 1)]\n",
    "\n",
    "exog_seasonal_order = {}\n",
    "exog_seasonal_order['Temp'] = [(0, 1, 1, 1461), (0, 1, 1, 1461), (0, 1, 1, 1461), (0, 0, 1, 1461), (0, 1, 0, 1461), (0, 1, 1, 1461)]\n",
    "exog_seasonal_order['WindSpeed'] = [(0, 1, 1, 1461), (0, 1, 1, 1461), (0, 1, 1, 1461), (0, 1, 1, 1461), (0, 0, 0, 1461), (0, 1, 1, 1461)]\n",
    "exog_seasonal_order['WindDir'] = [(1, 1, 0, 1461), (0, 1, 0, 1461), (1, 0, 0, 1461), (1, 1, 0, 1461), (0, 1, 1, 1461), (0, 1, 1, 1461)]\n",
    "\n",
    "exog_columns = ['Temp', 'WindSpeed', 'WindDir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "model_exog = {}\n",
    "\n",
    "for i, p in enumerate(province):\n",
    "    model[p] = MinimalSARIMAX(train_data[p][['PM25']],\n",
    "                order[i],\n",
    "                seasonal_order[i],\n",
    "                exog=train_data[p][exog_columns])\n",
    "    \n",
    "    model_exog[p] = {}    \n",
    "    for exog in exog_columns:\n",
    "        model_exog[p][exog] = MinimalSARIMAX(train_data[p][[exog]],\n",
    "                                            exog_order[exog][i],\n",
    "                                            exog_seasonal_order[exog][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in province:\n",
    "    model[p].fit(lr=1e-5, lr_decay=0.999 ,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in province:\n",
    "    for exog in exog_columns:\n",
    "        if exog == 'WindDir':\n",
    "            model_exog[p][exog].fit(lr=5e-7, lr_decay=0.999, verbose=0)\n",
    "        else:\n",
    "            model_exog[p][exog].fit(lr=1e-5, lr_decay=0.999, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = model['BKK'].predict_step(valid_set['BKK'][['PM25']],\n",
    "                                    test_data['BKK'][['PM25']], \n",
    "                                    val_X_exog=valid_set['BKK'][exog_columns],\n",
    "                                    y_exog=test_data['BKK'][exog_columns],\n",
    "                                    model_exog=model_exog['BKK'],\n",
    "                                    lr=1e-8, lr_decay=0.9999,\n",
    "                                    learn=True)\n",
    "\n",
    "val_pred_sav, y_pred_sav, Valid_Error, Test_Error = Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid_Error: 17.480863413514932\n",
      "Test_Error: 19.385899682672584\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valid_Error: {((Valid_Error**2).mean())**(1/2)}\")\n",
    "print(f\"Test_Error: {((Test_Error**2).mean())**(1/2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid_Error: 9.55376337957822\n",
      "Test_Error: 6.112386837356341\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valid_Error: {((Valid_Error**2).mean())**(1/2)}\")\n",
    "print(f\"Test_Error: {((Test_Error**2).mean())**(1/2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_sav.to_csv('answer_dataset/val_pred_sav.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Predict</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01 00:00:00</td>\n",
       "      <td>9.951314</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-01 06:00:00</td>\n",
       "      <td>9.816626</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-01 12:00:00</td>\n",
       "      <td>9.380869</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-01 18:00:00</td>\n",
       "      <td>9.072725</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-02 00:00:00</td>\n",
       "      <td>9.018758</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17497</th>\n",
       "      <td>2021-07-01 12:00:00</td>\n",
       "      <td>2.687520</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>2021-07-01 18:00:00</td>\n",
       "      <td>11.351331</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17499</th>\n",
       "      <td>2021-07-01 12:00:00</td>\n",
       "      <td>16.374167</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17500</th>\n",
       "      <td>2021-07-01 18:00:00</td>\n",
       "      <td>2.392909</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17501</th>\n",
       "      <td>2021-07-01 18:00:00</td>\n",
       "      <td>19.241681</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17502 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time    Predict  Actual\n",
       "0     2020-07-01 00:00:00   9.951314     9.0\n",
       "1     2020-07-01 06:00:00   9.816626    11.0\n",
       "2     2020-07-01 12:00:00   9.380869    15.0\n",
       "3     2020-07-01 18:00:00   9.072725    14.0\n",
       "4     2020-07-02 00:00:00   9.018758    18.0\n",
       "...                   ...        ...     ...\n",
       "17497 2021-07-01 12:00:00   2.687520    14.0\n",
       "17498 2021-07-01 18:00:00  11.351331    14.0\n",
       "17499 2021-07-01 12:00:00  16.374167    14.0\n",
       "17500 2021-07-01 18:00:00   2.392909    14.0\n",
       "17501 2021-07-01 18:00:00  19.241681    14.0\n",
       "\n",
       "[17502 rows x 3 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sav.to_csv('answer_dataset/y_pred_sav.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnx_data = pd.concat((cnx_train, cnx_valid, cnx_test), axis=0)\n",
    "# bkk_data = pd.concat((bkk_train, bkk_valid, bkk_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cnx.plot(cnx_data['PM25'], cnx_y_pred['PM25'], \"Chiangmai PM2.5 Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model['BKK'].plot(model['BKK']['PM25'], bkk_y_pred['PM25'], \"Bangkok PM2.5 Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0),\n",
       " (0, 0, 1),\n",
       " (0, 0, 2),\n",
       " (0, 1, 0),\n",
       " (0, 1, 1),\n",
       " (0, 1, 2),\n",
       " (0, 2, 0),\n",
       " (0, 2, 1),\n",
       " (0, 2, 2),\n",
       " (1, 0, 0),\n",
       " (1, 0, 1),\n",
       " (1, 0, 2),\n",
       " (1, 1, 0),\n",
       " (1, 1, 1),\n",
       " (1, 1, 2),\n",
       " (1, 2, 0),\n",
       " (1, 2, 1),\n",
       " (1, 2, 2),\n",
       " (2, 0, 0),\n",
       " (2, 0, 1),\n",
       " (2, 0, 2),\n",
       " (2, 1, 0),\n",
       " (2, 1, 1),\n",
       " (2, 1, 2),\n",
       " (2, 2, 0),\n",
       " (2, 2, 1),\n",
       " (2, 2, 2)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = d = q = range(0, 3)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "pdq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0, 1461),\n",
       " (0, 0, 1, 1461),\n",
       " (0, 0, 2, 1461),\n",
       " (0, 1, 0, 1461),\n",
       " (0, 1, 1, 1461),\n",
       " (0, 1, 2, 1461),\n",
       " (0, 2, 0, 1461),\n",
       " (0, 2, 1, 1461),\n",
       " (0, 2, 2, 1461),\n",
       " (1, 0, 0, 1461),\n",
       " (1, 0, 1, 1461),\n",
       " (1, 0, 2, 1461),\n",
       " (1, 1, 0, 1461),\n",
       " (1, 1, 1, 1461),\n",
       " (1, 1, 2, 1461),\n",
       " (1, 2, 0, 1461),\n",
       " (1, 2, 1, 1461),\n",
       " (1, 2, 2, 1461),\n",
       " (2, 0, 0, 1461),\n",
       " (2, 0, 1, 1461),\n",
       " (2, 0, 2, 1461),\n",
       " (2, 1, 0, 1461),\n",
       " (2, 1, 1, 1461),\n",
       " (2, 1, 2, 1461),\n",
       " (2, 2, 0, 1461),\n",
       " (2, 2, 1, 1461),\n",
       " (2, 2, 2, 1461)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdqs = [(x[0], x[1], x[2], 1461) for x in list(itertools.product(p, d, q))]\n",
    "pdqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "def sarimax_gridsearch(y_train, y_test, pdq, PDQs, y_val = None, x_train = None, x_test = None, x_val = None, verbose=0, model_exog=None):\n",
    "    '''\n",
    "    Input: \n",
    "        y_train: training data\n",
    "        y_test: test data\n",
    "        pdq : ARIMA combinations \n",
    "        pdqs : seasonal ARIMA combinations \n",
    "        x_train: exogenous training data\n",
    "        x_test: exogenous test data\n",
    "\n",
    "    Return:\n",
    "        Returns dataframe of parameter combinations with the least RMSE\n",
    "    '''\n",
    "    tqdm_disable = True\n",
    "    if verbose: tqdm_disable = False\n",
    "\n",
    "    ans_df = pd.DataFrame(columns=['pdq', 'pdqs', 'rmse'])\n",
    "    \n",
    "    for comb in tqdm(pdq, disable=tqdm_disable):\n",
    "        for combs in PDQs:\n",
    "            p, d, q = comb[0], comb[1], comb[2]\n",
    "            P, D, Q = combs[0], combs[1], combs[2]\n",
    "            if (p+q <= 2) and (d <= 1) and (D <= 1) and (P <= 1) and (Q <= 1):  \n",
    "                # try:\n",
    "                    model = MinimalSARIMAX(y_train, comb, combs, exog=x_train)\n",
    "                    model.fit(lr=5e-7, lr_decay=0.999 ,verbose=0) \n",
    "\n",
    "                    if (y_val is None):\n",
    "                        y_pred, err = model.predict(y_test, y_exog=x_test, verbose=0)\n",
    "                        # y_pred = y_pred[:-1] # remove last value since it's a list of all the predicted values which makes the scoring fail (inconsistent shape with the y_test)\n",
    "                        rmse = model.scoring(y_pred, y_test)\n",
    "\n",
    "                    else:\n",
    "                        Result = model.predict_step(y_val, y_test, val_X_exog=x_val, y_exog=x_test,\n",
    "                                                    model_exog=model_exog, lr=1e-8, lr_decay=0.9999, learn=False)\n",
    "\n",
    "                        _, y_pred_sav, _, _ = Result\n",
    "                        \n",
    "                        rmse = model.scoring(y_pred_sav.iloc[:,[1]], y_pred_sav.iloc[:,[2]])\n",
    "                    \n",
    "\n",
    "                    ans_df = ans_df.append({'pdq':comb, 'pdqs':combs, 'rmse':rmse}, ignore_index=True)\n",
    "                    # print(f'SARIMAX {comb} x {combs} : RMSE Calculated ={rmse}')\n",
    "                # except Exception as e: \n",
    "                #     # print(e)\n",
    "                #     continue\n",
    "\n",
    "    # Convert into a dataframe\n",
    "    # ans_df = pd.DataFrame(ans, columns=['pdq', 'pdqs', 'rmse'])\n",
    "\n",
    "    # Sort and return a combination with the lowest RMSE\n",
    "    ans_df = ans_df.sort_values(by=['rmse'],ascending=True)\n",
    "    \n",
    "    return ans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.7\n",
    "\n",
    "pm_train_bkk = train_data[province[0]][['PM25']][:int(ratio*train_data[province[0]].shape[0])]\n",
    "pm_valid_bkk = train_data[province[0]][['PM25']][int(ratio*train_data[province[0]].shape[0]):]\n",
    "pm_test_bkk = test_data[province[0]][['PM25']]\n",
    "exo_train_bkk = train_data[province[0]][exog_columns][:int(ratio*train_data[province[0]].shape[0])]\n",
    "exo_valid_bkk = train_data[province[0]][exog_columns][int(ratio*train_data[province[0]].shape[0]):]\n",
    "exo_test_bkk = test_data[province[0]][exog_columns]\n",
    "\n",
    "\n",
    "pm_train_cnx = train_data[province[1]][['PM25']][:int(ratio*train_data[province[0]].shape[0])]\n",
    "pm_valid_cnx = train_data[province[1]][['PM25']][int(ratio*train_data[province[0]].shape[0]):]\n",
    "pm_test_cnx = test_data[province[1]][['PM25']]\n",
    "exo_train_cnx = train_data[province[1]][exog_columns][:int(ratio*train_data[province[0]].shape[0])]\n",
    "exo_valid_cnx = train_data[province[1]][exog_columns][int(ratio*train_data[province[0]].shape[0]):]\n",
    "exo_test_cnx = test_data[province[1]][exog_columns]\n",
    "\n",
    "\n",
    "pm_train_kkc = train_data[province[2]][['PM25']][:int(ratio*train_data[province[0]].shape[0])]\n",
    "pm_valid_kkc = train_data[province[2]][['PM25']][int(ratio*train_data[province[0]].shape[0]):]\n",
    "pm_test_kkc = test_data[province[2]][['PM25']]\n",
    "exo_train_kkc = train_data[province[2]][exog_columns][:int(ratio*train_data[province[0]].shape[0])]\n",
    "exo_valid_kkc = train_data[province[2]][exog_columns][int(ratio*train_data[province[0]].shape[0]):]\n",
    "exo_test_kkc = test_data[province[2]][exog_columns]\n",
    "\n",
    "\n",
    "pm_train_ray = train_data[province[3]][['PM25']][:int(ratio*train_data[province[0]].shape[0])]\n",
    "pm_valid_ray = train_data[province[3]][['PM25']][int(ratio*train_data[province[0]].shape[0]):]\n",
    "pm_test_ray = test_data[province[3]][['PM25']]\n",
    "exo_train_ray = train_data[province[3]][exog_columns][:int(ratio*train_data[province[0]].shape[0])]\n",
    "exo_valid_ray = train_data[province[3]][exog_columns][int(ratio*train_data[province[0]].shape[0]):]\n",
    "exo_test_ray = test_data[province[3]][exog_columns]\n",
    "\n",
    "\n",
    "pm_train_sara = train_data[province[4]][['PM25']][:int(ratio*train_data[province[0]].shape[0])]\n",
    "pm_valid_sara = train_data[province[4]][['PM25']][int(ratio*train_data[province[0]].shape[0]):]\n",
    "pm_test_sara = test_data[province[4]][['PM25']]\n",
    "exo_train_sara = train_data[province[4]][exog_columns][:int(ratio*train_data[province[0]].shape[0])]\n",
    "exo_valid_sara = train_data[province[4]][exog_columns][int(ratio*train_data[province[0]].shape[0]):]\n",
    "exo_test_sara = test_data[province[4]][exog_columns]\n",
    "\n",
    "\n",
    "pm_train_surat = train_data[province[5]][['PM25']][:int(ratio*train_data[province[0]].shape[0])]\n",
    "pm_valid_surat = train_data[province[5]][['PM25']][int(ratio*train_data[province[0]].shape[0]):]\n",
    "pm_test_surat = test_data[province[5]][['PM25']]\n",
    "exo_train_surat = train_data[province[5]][exog_columns][:int(ratio*train_data[province[0]].shape[0])]\n",
    "exo_valid_surat = train_data[province[5]][exog_columns][int(ratio*train_data[province[0]].shape[0]):]\n",
    "exo_test_surat = test_data[province[5]][exog_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters for PM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bkk = sarimax_gridsearch(pm_train_bkk, pm_test_bkk, pdq, pdqs, y_val=pm_valid_bkk, x_train=exo_train_bkk, x_test=exo_test_bkk, x_val=exo_valid_bkk)\n",
    "result_cnx = sarimax_gridsearch(pm_train_cnx, pm_test_cnx, pdq, pdqs, y_val=pm_valid_cnx, x_train=exo_train_cnx, x_test=exo_test_cnx, x_val=exo_valid_cnx)\n",
    "result_kkc = sarimax_gridsearch(pm_train_kkc, pm_test_kkc, pdq, pdqs, y_val=pm_valid_kkc, x_train=exo_train_kkc, x_test=exo_test_kkc, x_val=exo_valid_kkc)\n",
    "result_ray = sarimax_gridsearch(pm_train_ray, pm_test_ray, pdq, pdqs, y_val=pm_valid_ray, x_train=exo_train_ray, x_test=exo_test_ray, x_val=exo_valid_ray)\n",
    "result_sara = sarimax_gridsearch(pm_train_sara, pm_test_sara, pdq, pdqs, y_val=pm_valid_sara, x_train=exo_train_sara, x_test=exo_test_sara, x_val=exo_valid_sara)\n",
    "result_surat = sarimax_gridsearch(pm_train_surat, pm_test_surat, pdq, pdqs, y_val=pm_valid_surat, x_train=exo_train_surat, x_test=exo_test_surat, x_val=exo_valid_surat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_dataset/resulk_bkk_03.bin',\"wb\") as f:\n",
    "    pickle.dump(result_bkk, f)\n",
    "\n",
    "with open('answer_dataset/resulk_cnx_03.bin',\"wb\") as f:\n",
    "    pickle.dump(result_cnx, f)\n",
    "    \n",
    "with open('answer_dataset/resulk_ray_03.bin',\"wb\") as f:\n",
    "    pickle.dump(result_bkk, f)\n",
    "\n",
    "with open('answer_dataset/resulk_sara_03.bin',\"wb\") as f:\n",
    "    pickle.dump(result_sara, f)\n",
    "\n",
    "with open('answer_dataset/resulk_surat_03.bin',\"wb\") as f:\n",
    "    pickle.dump(result_surat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BKK': (2, 1, 0), 'CNX': (1, 0, 1), 'KKC': (2, 1, 0), 'RAY': (2, 1, 0), 'SARA': (2, 0, 0), 'SURAT': (2, 1, 0)}\n",
      "{'BKK': (1, 1, 0, 1461), 'CNX': (0, 1, 1, 1461), 'KKC': (0, 1, 0, 1461), 'RAY': (0, 1, 0, 1461), 'SARA': (0, 0, 0, 1461), 'SURAT': (0, 1, 1, 1461)}\n"
     ]
    }
   ],
   "source": [
    "order = {province[0]: result_bkk.pdq, province[1]: result_cnx.pdq, province[2]: result_kkc.pdq, province[3]: result_ray.pdq, province[4]: result_sara.pdq, province[5]: result_surat.pdq}\n",
    "seasonal_order = {province[0]: result_bkk.pdqs, province[1]: result_cnx.pdqs, province[2]: result_kkc.pdqs, province[3]: result_ray.pdqs, province[4]: result_sara.pdqs, province[5]: result_surat.pdqs}\n",
    "print(order)\n",
    "print(seasonal_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters for temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = exog_columns[0]\n",
    "temp_train_bkk = pd.DataFrame(exo_train_bkk[temp])\n",
    "temp_test_bkk = pd.DataFrame(exo_test_bkk[temp])\n",
    "\n",
    "temp_train_cnx = pd.DataFrame(exo_train_cnx[temp])\n",
    "temp_test_cnx = pd.DataFrame(exo_test_cnx[temp])\n",
    "\n",
    "temp_train_kkc = pd.DataFrame(exo_train_kkc[temp])\n",
    "temp_test_kkc = pd.DataFrame(exo_test_kkc[temp])\n",
    "\n",
    "temp_train_ray = pd.DataFrame(exo_train_ray[temp])\n",
    "temp_test_ray = pd.DataFrame(exo_test_ray[temp])\n",
    "\n",
    "temp_train_sara = pd.DataFrame(exo_train_sara[temp])\n",
    "temp_test_sara = pd.DataFrame(exo_test_sara[temp])\n",
    "\n",
    "temp_train_surat = pd.DataFrame(exo_train_surat[temp])\n",
    "temp_test_surat = pd.DataFrame(exo_test_surat[temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSearch_temp_bkk = sarimax_gridsearch(temp_train_bkk, temp_test_bkk, pdq, pdqs)\n",
    "gSearch_temp_cnx = sarimax_gridsearch(temp_train_cnx, temp_test_cnx, pdq, pdqs)\n",
    "gSearch_temp_kkc = sarimax_gridsearch(temp_train_kkc, temp_test_kkc, pdq, pdqs)\n",
    "gSearch_temp_ray = sarimax_gridsearch(temp_train_ray, temp_test_ray, pdq, pdqs)\n",
    "gSearch_temp_sara = sarimax_gridsearch(temp_train_sara, temp_test_sara, pdq, pdqs)\n",
    "gSearch_temp_surat = sarimax_gridsearch(temp_train_surat, temp_test_surat, pdq, pdqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BKK': (1, 0, 0), 'CNX': (1, 1, 0), 'KKC': (1, 0, 0), 'RAY': (1, 0, 0), 'SARA': (1, 0, 0), 'SURAT': (1, 0, 0)}\n",
      "{'BKK': (0, 0, 0, 1461), 'CNX': (0, 0, 0, 1461), 'KKC': (0, 0, 0, 1461), 'RAY': (0, 0, 1, 1461), 'SARA': (0, 0, 0, 1461), 'SURAT': (0, 0, 1, 1461)}\n"
     ]
    }
   ],
   "source": [
    "temp_order = {province[0]: gSearch_temp_bkk.pdq, province[1]: gSearch_temp_cnx.pdq, province[2]: gSearch_temp_kkc.pdq, province[3]: gSearch_temp_ray.pdq, province[4]: gSearch_temp_sara.pdq, province[5]: gSearch_temp_surat.pdq}\n",
    "temp_seasonal_order = {province[0]: gSearch_temp_bkk.pdqs, province[1]: gSearch_temp_cnx.pdqs, province[2]: gSearch_temp_kkc.pdqs, province[3]: gSearch_temp_ray.pdqs, province[4]: gSearch_temp_sara.pdqs, province[5]: gSearch_temp_surat.pdqs}\n",
    "print(temp_order)\n",
    "print(temp_seasonal_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters for windspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "windSpeed = exog_columns[1]\n",
    "windSpeed_train_bkk = pd.DataFrame(exo_train_bkk[windSpeed])\n",
    "windSpeed_valid_bkk = pd.DataFrame(exo_valid_bkk[windSpeed])\n",
    "windSpeed_test_bkk = pd.DataFrame(exo_test_bkk[windSpeed])\n",
    "\n",
    "windSpeed_train_cnx = pd.DataFrame(exo_train_cnx[windSpeed])\n",
    "windSpeed_valid_cnx = pd.DataFrame(exo_valid_cnx[windSpeed])\n",
    "windSpeed_test_cnx = pd.DataFrame(exo_test_cnx[windSpeed])\n",
    "\n",
    "windSpeed_train_kkc = pd.DataFrame(exo_train_kkc[windSpeed])\n",
    "windSpeed_valid_kkc = pd.DataFrame(exo_valid_kkc[windSpeed])\n",
    "windSpeed_test_kkc = pd.DataFrame(exo_test_kkc[windSpeed])\n",
    "\n",
    "windSpeed_train_ray = pd.DataFrame(exo_train_ray[windSpeed])\n",
    "windSpeed_valid_ray = pd.DataFrame(exo_valid_ray[windSpeed])\n",
    "windSpeed_test_ray = pd.DataFrame(exo_test_ray[windSpeed])\n",
    "\n",
    "windSpeed_train_sara = pd.DataFrame(exo_train_sara[windSpeed])\n",
    "windSpeed_valid_sara = pd.DataFrame(exo_valid_sara[windSpeed])\n",
    "windSpeed_test_sara = pd.DataFrame(exo_test_sara[windSpeed])\n",
    "\n",
    "windSpeed_train_surat = pd.DataFrame(exo_train_surat[windSpeed])\n",
    "windSpeed_valid_surat = pd.DataFrame(exo_valid_surat[windSpeed])\n",
    "windSpeed_test_surat = pd.DataFrame(exo_test_surat[windSpeed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSearch_windSpeed_bkk = sarimax_gridsearch(windSpeed_train_bkk, windSpeed_test_bkk, pdq, pdqs, y_val=windSpeed_valid_bkk)\n",
    "gSearch_windSpeed_cnx = sarimax_gridsearch(windSpeed_train_cnx, windSpeed_test_cnx, pdq, pdqs, y_val=windSpeed_valid_cnx)\n",
    "gSearch_windSpeed_kkc = sarimax_gridsearch(windSpeed_train_kkc, windSpeed_test_kkc, pdq, pdqs, y_val=windSpeed_valid_kkc)\n",
    "gSearch_windSpeed_ray = sarimax_gridsearch(windSpeed_train_ray, windSpeed_test_ray, pdq, pdqs, y_val=windSpeed_valid_ray)\n",
    "gSearch_windSpeed_sara = sarimax_gridsearch(windSpeed_train_sara, windSpeed_test_sara, pdq, pdqs, y_val=windSpeed_valid_sara)\n",
    "gSearch_windSpeed_surat = sarimax_gridsearch(windSpeed_train_surat, windSpeed_test_surat, pdq, pdqs, y_val=windSpeed_valid_surat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BKK': (1, 1, 0), 'CNX': (1, 1, 0), 'KKC': (1, 1, 0), 'RAY': (1, 1, 0), 'SARA': (1, 0, 0), 'SURAT': (1, 1, 0)}\n",
      "{'BKK': (0, 1, 1, 1461), 'CNX': (0, 1, 1, 1461), 'KKC': (0, 1, 1, 1461), 'RAY': (0, 1, 1, 1461), 'SARA': (0, 0, 0, 1461), 'SURAT': (0, 1, 1, 1461)}\n"
     ]
    }
   ],
   "source": [
    "windSpeed_order = {province[0]: gSearch_windSpeed_bkk.pdq, province[1]: gSearch_windSpeed_cnx.pdq, province[2]: gSearch_windSpeed_kkc.pdq, province[3]: gSearch_windSpeed_ray.pdq, province[4]: gSearch_windSpeed_sara.pdq, province[5]: gSearch_windSpeed_surat.pdq}\n",
    "windSpeed_seasonal_order = {province[0]: gSearch_windSpeed_bkk.pdqs, province[1]: gSearch_windSpeed_cnx.pdqs, province[2]: gSearch_windSpeed_kkc.pdqs, province[3]: gSearch_windSpeed_ray.pdqs, province[4]: gSearch_windSpeed_sara.pdqs, province[5]: gSearch_windSpeed_surat.pdqs}\n",
    "print(windSpeed_order)\n",
    "print(windSpeed_seasonal_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters for wind direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "windDir = exog_columns[2]\n",
    "\n",
    "windDir_train_bkk = pd.DataFrame(exo_train_bkk[windDir])\n",
    "windDir_valid_bkk = pd.DataFrame(exo_valid_bkk[windDir])\n",
    "windDir_test_bkk = pd.DataFrame(exo_test_bkk[windDir])\n",
    "\n",
    "windDir_train_cnx = pd.DataFrame(exo_train_cnx[windDir])\n",
    "windDir_valid_cnx = pd.DataFrame(exo_valid_cnx[windDir])\n",
    "windDir_test_cnx = pd.DataFrame(exo_test_cnx[windDir])\n",
    "\n",
    "windDir_train_kkc = pd.DataFrame(exo_train_kkc[windDir])\n",
    "windDir_valid_kkc = pd.DataFrame(exo_valid_kkc[windDir])\n",
    "windDir_test_kkc = pd.DataFrame(exo_test_kkc[windDir])\n",
    "\n",
    "windDir_train_ray = pd.DataFrame(exo_train_ray[windDir])\n",
    "windDir_valid_ray = pd.DataFrame(exo_valid_ray[windDir])\n",
    "windDir_test_ray = pd.DataFrame(exo_test_ray[windDir])\n",
    "\n",
    "windDir_train_sara = pd.DataFrame(exo_train_sara[windDir])\n",
    "windDir_valid_sara = pd.DataFrame(exo_valid_sara[windDir])\n",
    "windDir_test_sara = pd.DataFrame(exo_test_sara[windDir])\n",
    "\n",
    "windDir_train_surat = pd.DataFrame(exo_train_surat[windDir])\n",
    "windDir_valid_surat = pd.DataFrame(exo_valid_surat[windDir])\n",
    "windDir_test_surat = pd.DataFrame(exo_test_surat[windDir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSearch_windDir_bkk = sarimax_gridsearch(windDir_train_bkk, windDir_test_bkk, pdq, pdqs, y_val=windDir_valid_bkk)\n",
    "gSearch_windDir_cnx = sarimax_gridsearch(windDir_train_cnx, windDir_test_cnx, pdq, pdqs, y_val=windDir_valid_bkk)\n",
    "gSearch_windDir_kkc = sarimax_gridsearch(windDir_train_kkc, windDir_test_kkc, pdq, pdqs, y_val=windDir_valid_bkk)\n",
    "gSearch_windDir_ray = sarimax_gridsearch(windDir_train_ray, windDir_test_ray, pdq, pdqs, y_val=windDir_valid_bkk)\n",
    "gSearch_windDir_sara = sarimax_gridsearch(windDir_train_sara, windDir_test_sara, pdq, pdqs, y_val=windDir_valid_bkk)\n",
    "gSearch_windDir_surat = sarimax_gridsearch(windDir_train_surat, windDir_test_surat, pdq, pdqs, y_val=windDir_valid_bkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BKK': (1, 1, 0), 'CNX': (1, 1, 0), 'KKC': (2, 1, 0), 'RAY': (1, 0, 1), 'SARA': (1, 1, 0), 'SURAT': (1, 1, 1)}\n",
      "{'BKK': (0, 1, 1, 1461), 'CNX': (1, 1, 0, 1461), 'KKC': (1, 1, 0, 1461), 'RAY': (0, 1, 0, 1461), 'SARA': (0, 0, 1, 1461), 'SURAT': (0, 1, 0, 1461)}\n"
     ]
    }
   ],
   "source": [
    "windDir_order = {province[0]: gSearch_windDir_bkk.pdq, province[1]: gSearch_windDir_cnx.pdq, province[2]: gSearch_windDir_kkc.pdq, province[3]: gSearch_windDir_ray.pdq, province[4]: gSearch_windDir_sara.pdq, province[5]: gSearch_windDir_surat.pdq}\n",
    "windDir_seasonal_order = {province[0]: gSearch_windDir_bkk.pdqs, province[1]: gSearch_windDir_cnx.pdqs, province[2]: gSearch_windDir_kkc.pdqs, province[3]: gSearch_windDir_ray.pdqs, province[4]: gSearch_windDir_sara.pdqs, province[5]: gSearch_windDir_surat.pdqs}\n",
    "print(windDir_order)\n",
    "print(windDir_seasonal_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_dataset/gSearch_windDir_bkk_03.bin',\"wb\") as f:\n",
    "    pickle.dump(gSearch_windDir_bkk, f)\n",
    "\n",
    "with open('answer_dataset/gSearch_windDir_cnx_03.bin',\"wb\") as f:\n",
    "    pickle.dump(gSearch_windDir_cnx, f)\n",
    "    \n",
    "with open('answer_dataset/gSearch_windDir_ray_03.bin',\"wb\") as f:\n",
    "    pickle.dump(gSearch_windDir_bkk, f)\n",
    "\n",
    "with open('answer_dataset/gSearch_windDir_sara_03.bin',\"wb\") as f:\n",
    "    pickle.dump(gSearch_windDir_sara, f)\n",
    "\n",
    "with open('answer_dataset/gSearch_windDir_surat_03.bin',\"wb\") as f:\n",
    "    pickle.dump(gSearch_windDir_surat, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project_nb.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
